{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(x):\n",
    "    1/(1+np.exp**(-x))\n",
    "def sigmoid_derivative(x):\n",
    "    return x * (1 - x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input Data:\n",
      "[[0.37454012 0.95071431]\n",
      " [0.73199394 0.59865848]\n",
      " [0.15601864 0.15599452]\n",
      " [0.05808361 0.86617615]\n",
      " [0.60111501 0.70807258]]\n",
      "\n",
      "Output Data:\n",
      "[[0.64203165]\n",
      " [0.08413996]\n",
      " [0.16162871]\n",
      " [0.89855419]\n",
      " [0.60642906]]\n",
      "Epoch 0, Loss: 0.10384838392009973\n",
      "Epoch 200, Loss: 0.04250882754196847\n",
      "Epoch 400, Loss: 0.04241717464093795\n",
      "Epoch 600, Loss: 0.04240495452316893\n",
      "Epoch 800, Loss: 0.042402137388254504\n",
      "Epoch 1000, Loss: 0.042399330678301046\n",
      "Epoch 1200, Loss: 0.04239573707421442\n",
      "Epoch 1400, Loss: 0.0424061077019188\n",
      "Epoch 1600, Loss: 0.042397124944337186\n",
      "Epoch 1800, Loss: 0.042401150807938055\n",
      "Epoch 2000, Loss: 0.042478723412266384\n",
      "Epoch 2200, Loss: 0.042566881784634365\n",
      "Epoch 2400, Loss: 0.042494285499402686\n",
      "Epoch 2600, Loss: 0.0425645486900369\n",
      "Epoch 2800, Loss: 0.042578256293743344\n",
      "Epoch 3000, Loss: 0.04257774111004837\n",
      "Epoch 3200, Loss: 0.04257899253170723\n",
      "Epoch 3400, Loss: 0.042564539036999104\n",
      "Epoch 3600, Loss: 0.04252632121562432\n",
      "Epoch 3800, Loss: 0.04246180710710276\n",
      "Epoch 4000, Loss: 0.042372785113094585\n",
      "Epoch 4200, Loss: 0.04226429326928244\n",
      "Epoch 4400, Loss: 0.042142740001591746\n",
      "Epoch 4600, Loss: 0.04201489814091655\n",
      "Epoch 4800, Loss: 0.041887658891005236\n",
      "Epoch 5000, Loss: 0.04176841853011977\n",
      "Epoch 5200, Loss: 0.041664165262571\n",
      "Epoch 5400, Loss: 0.04157915051606973\n",
      "Epoch 5600, Loss: 0.04151381195545747\n",
      "Epoch 5800, Loss: 0.041465715315399464\n",
      "Epoch 6000, Loss: 0.04143120827507747\n",
      "Epoch 6200, Loss: 0.041406696406259484\n",
      "Epoch 6400, Loss: 0.04138927671932675\n",
      "Epoch 6600, Loss: 0.04137686656183544\n",
      "Epoch 6800, Loss: 0.041368019675939734\n",
      "Epoch 7000, Loss: 0.04136158659056594\n",
      "Epoch 7200, Loss: 0.041356450856028674\n",
      "Epoch 7400, Loss: 0.04135167452654007\n",
      "Epoch 7600, Loss: 0.041346928260797826\n",
      "Epoch 7800, Loss: 0.04134246665044408\n",
      "Epoch 8000, Loss: 0.04133858074916273\n",
      "Epoch 8200, Loss: 0.04133522679251673\n",
      "Epoch 8400, Loss: 0.041332114270532676\n",
      "Epoch 8600, Loss: 0.04132902234854794\n",
      "Epoch 8800, Loss: 0.04132597631465489\n",
      "Epoch 9000, Loss: 0.04132312931133745\n",
      "Epoch 9200, Loss: 0.041320558142986456\n",
      "Epoch 9400, Loss: 0.04131820378347733\n",
      "Epoch 9600, Loss: 0.04131595905933068\n",
      "Epoch 9800, Loss: 0.041313773499522775\n",
      "\n",
      "Predictions after training:\n",
      "[[0.45315098]\n",
      " [0.50531557]\n",
      " [0.61355164]\n",
      " [0.46281656]\n",
      " [0.484953  ]\n",
      " [0.45555486]\n",
      " [0.51911064]\n",
      " [0.58181479]\n",
      " [0.46590176]\n",
      " [0.47818802]\n",
      " [0.49095768]\n",
      " [0.48551289]\n",
      " [0.46435069]\n",
      " [0.48428547]\n",
      " [0.49321283]\n",
      " [0.48977814]\n",
      " [0.44919113]\n",
      " [0.54859857]\n",
      " [0.53405343]\n",
      " [0.4968048 ]\n",
      " [0.51898706]\n",
      " [0.4619443 ]\n",
      " [0.45721875]\n",
      " [0.46581843]\n",
      " [0.48532803]\n",
      " [0.54887689]\n",
      " [0.5450481 ]\n",
      " [0.48583529]\n",
      " [0.65868316]\n",
      " [0.64122424]\n",
      " [0.48255783]\n",
      " [0.51948451]\n",
      " [0.46612903]\n",
      " [0.45505276]\n",
      " [0.44326871]\n",
      " [0.50968185]\n",
      " [0.49223818]\n",
      " [0.50225667]\n",
      " [0.50973299]\n",
      " [0.50982572]\n",
      " [0.52809543]\n",
      " [0.53069549]\n",
      " [0.48759425]\n",
      " [0.50524983]\n",
      " [0.53061149]\n",
      " [0.4720594 ]\n",
      " [0.50981223]\n",
      " [0.510947  ]\n",
      " [0.47631356]\n",
      " [0.76352603]\n",
      " [0.52905885]\n",
      " [0.466621  ]\n",
      " [0.5318752 ]\n",
      " [0.45936719]\n",
      " [0.58606567]\n",
      " [0.52506127]\n",
      " [0.54218188]\n",
      " [0.49126485]\n",
      " [0.51445025]\n",
      " [0.53229973]\n",
      " [0.52156452]\n",
      " [0.5251986 ]\n",
      " [0.49166163]\n",
      " [0.52299621]\n",
      " [0.59454187]\n",
      " [0.48471782]\n",
      " [0.57113851]\n",
      " [0.53870901]\n",
      " [0.47294306]\n",
      " [0.45167895]\n",
      " [0.54135308]\n",
      " [0.47832241]\n",
      " [0.56188131]\n",
      " [0.48594197]\n",
      " [0.65677757]\n",
      " [0.53190616]\n",
      " [0.50932625]\n",
      " [0.54529278]\n",
      " [0.49673705]\n",
      " [0.45315376]\n",
      " [0.45917127]\n",
      " [0.48937886]\n",
      " [0.45988675]\n",
      " [0.50811913]\n",
      " [0.53787367]\n",
      " [0.49965182]\n",
      " [0.48218328]\n",
      " [0.49326559]\n",
      " [0.49773024]\n",
      " [0.53584354]\n",
      " [0.5158051 ]\n",
      " [0.54217852]\n",
      " [0.45746645]\n",
      " [0.51936032]\n",
      " [0.4822191 ]\n",
      " [0.45097823]\n",
      " [0.5347912 ]\n",
      " [0.47992026]\n",
      " [0.50729081]\n",
      " [0.53423486]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "\n",
    "def sigmoid_derivative(x):\n",
    "    return x * (1 - x)\n",
    "\n",
    "class nn():\n",
    "    def __init__(self, hidden, input, output):\n",
    "        self.input = input\n",
    "        self.hidden = hidden\n",
    "        self.output = output\n",
    "        self.weights_hidden = np.random.rand(self.input, self.hidden)\n",
    "        self.weights_output = np.random.rand(self.hidden, self.output)\n",
    "        self.bias_hidden = np.zeros((1, self.hidden))\n",
    "        self.bias_output = np.zeros((1, self.output))\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        self.hidden_input = np.dot(inputs, self.weights_hidden) + self.bias_hidden\n",
    "        self.hidden_output = sigmoid(self.hidden_input)\n",
    "\n",
    "        \n",
    "        self.output_input = np.dot(self.hidden_output, self.weights_output) + self.bias_output\n",
    "        self.predictions = sigmoid(self.output_input)\n",
    "\n",
    "        return self.predictions\n",
    "\n",
    "    def backward(self, inputs, targets, learning_rate):\n",
    "\n",
    "        output_error = targets - self.predictions\n",
    "        output_delta = output_error * sigmoid_derivative(self.predictions)\n",
    "\n",
    "        hidden_error = output_delta.dot(self.weights_output.T)\n",
    "        hidden_delta = hidden_error * sigmoid_derivative(self.hidden_output)\n",
    "\n",
    "        self.weights_output += self.hidden_output.T.dot(output_delta) * learning_rate\n",
    "        self.bias_output += np.sum(output_delta, axis=0, keepdims=True) * learning_rate\n",
    "        self.weights_hidden += inputs.T.dot(hidden_delta) * learning_rate\n",
    "        self.bias_hidden += np.sum(hidden_delta, axis=0, keepdims=True) * learning_rate\n",
    "\n",
    "    def train(self, inputs, targets, epochs, learning_rate):\n",
    "        for epoch in range(epochs):\n",
    "            predictions = self.forward(inputs)\n",
    "            self.backward(inputs, targets, learning_rate)\n",
    "\n",
    "            if epoch % 200 == 0:\n",
    "                loss = np.mean(np.square(targets - predictions) / 2)\n",
    "                print(f'Epoch {epoch}, Loss: {loss}')\n",
    "\n",
    "np.random.seed(42)\n",
    "num_samples = 100\n",
    "input_data = np.random.rand(num_samples, 2)\n",
    "output_data = np.random.rand(num_samples, 1)\n",
    "\n",
    "print(\"Input Data:\")\n",
    "print(input_data[:5])\n",
    "print(\"\\nOutput Data:\")\n",
    "print(output_data[:5])\n",
    "\n",
    "input_size = 2\n",
    "hidden_size = 7\n",
    "output_size = 1\n",
    "\n",
    "model = nn(hidden_size, input_size, output_size)\n",
    "model.train(input_data, output_data, epochs=10000, learning_rate=0.1)\n",
    "\n",
    "predictions = model.forward(input_data)\n",
    "print(\"\\nPredictions after training:\")\n",
    "print(predictions)\n",
    "\n",
    "            "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
